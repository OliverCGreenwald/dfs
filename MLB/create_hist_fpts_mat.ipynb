{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: set covariance to 0 if less than played in less than 10% of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"/Users/alandu/Documents/DFS/\")\n",
    "# from datetime import date, timedelta\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dateRange(start, end, delta):\n",
    "    dates = []\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        dates.append(curr)\n",
    "        curr += delta\n",
    "    dates = list(dates)\n",
    "#     output = [date.strftime('%Y-%m-%d') for date in dates]\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create first/base case hist_fpts_mat_update matrix (only need to run once at beginning of season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # first date\n",
    "# date = \"2017-04-02\"\n",
    "\n",
    "# results_mat = pd.read_csv(\"MLB/data_warehouse/\" + date + \"/player_results.csv\")\n",
    "# results_mat['Name_Team'] = results_mat['Player'] + \"_\" + results_mat['Team']\n",
    "# results_mat = results_mat[['Name_Team', 'Actual Score']]\n",
    "# results_mat.rename(columns={'Actual Score':date}, inplace = True)\n",
    "# results_mat\n",
    "\n",
    "# results_mat.to_csv(\"MLB/data_warehouse/\" + \"2017-04-03\" + \"/hist_fpts_mat_update.csv\", index=False, na_rep=\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create hist_fpts_mat_update for rest of season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date missing after 2017-07-10\n",
      "date missing after 2017-07-14\n",
      "date missing after 2017-07-17\n",
      "date missing after 2017-08-09\n"
     ]
    }
   ],
   "source": [
    "# this code could be cleaned up. got messy because missing some date folders due to missing data / all star break\n",
    "\n",
    "# rest of dates\n",
    "date_list = dateRange(datetime.date(2017, 4, 4), datetime.date(2017, 8, 15), datetime.timedelta(days=1))\n",
    "\n",
    "for date in date_list:\n",
    "    file_path_date = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d'))\n",
    "    if file_path_date.exists():\n",
    "        date_tm1 = date - datetime.timedelta(days=1)\n",
    "        \n",
    "        # read in hist_fpts_mat_update from date t-1\n",
    "        file_path_hist = Path(\"MLB/data_warehouse/\" + date_tm1.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "        if file_path_hist.exists():\n",
    "            hist_fpts_mat = pd.read_csv(str(file_path_hist))\n",
    "        else:\n",
    "            # fill in dates where folder is missing\n",
    "            temp_date = date_tm1 - datetime.timedelta(days=1)\n",
    "            file_path_hist = Path(\"MLB/data_warehouse/\" + temp_date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "            num_missing = 1\n",
    "            while (file_path_hist.exists() == False):\n",
    "                temp_date = temp_date - datetime.timedelta(days=1)\n",
    "                file_path_hist = Path(\"MLB/data_warehouse/\" + temp_date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "                num_missing += 1\n",
    "            hist_fpts_mat = pd.read_csv(str(file_path_hist))\n",
    "            print(\"date(s) missing after \" + date.strftime('%Y-%m-%d'))\n",
    "            for i in range(0,num_missing):\n",
    "                new_column = temp_date + datetime.timedelta(days=i+1)\n",
    "                \n",
    "                # add missing date\n",
    "                new_column_m1 = new_column - datetime.timedelta(days=1)\n",
    "#                 print(new_column_m1.strftime('%Y-%m-%d'))\n",
    "                file_path_results = Path(\"MLB/data_warehouse/\" + new_column_m1.strftime('%Y-%m-%d') + \"/player_results.csv\")\n",
    "                if file_path_results.exists():\n",
    "                    results_mat = pd.read_csv(str(file_path_results))\n",
    "                    results_mat['Name_Team'] = results_mat['Player'] + \"_\" + results_mat['Team']\n",
    "                    hist_fpts_mat = hist_fpts_mat.merge(results_mat[['Name_Team', 'Actual Score']], on=\"Name_Team\", how='outer')\n",
    "                    hist_fpts_mat.rename(columns={'Actual Score':new_column_m1.strftime('%Y-%m-%d')}, inplace = True)\n",
    "                elif Path(\"MLB/data_warehouse/\" + new_column_m1.strftime('%Y-%m-%d')).exists():\n",
    "                    hist_fpts_mat[new_column_m1.strftime('%Y-%m-%d')] = float('NaN')\n",
    "                \n",
    "                # add previous dates NA\n",
    "                hist_fpts_mat[new_column.strftime('%Y-%m-%d')] = float('NaN')\n",
    "        \n",
    "        # add fpts for date t\n",
    "        file_path_results = Path(\"MLB/data_warehouse/\" + date_tm1.strftime('%Y-%m-%d') + \"/player_results.csv\")\n",
    "        if file_path_results.exists():\n",
    "            results_mat = pd.read_csv(str(file_path_results))\n",
    "            results_mat['Name_Team'] = results_mat['Player'] + \"_\" + results_mat['Team']\n",
    "\n",
    "            new_hist_fpts_mat = hist_fpts_mat.merge(results_mat[['Name_Team', 'Actual Score']], on=\"Name_Team\", how='outer')\n",
    "            new_hist_fpts_mat.rename(columns={'Actual Score':date_tm1.strftime('%Y-%m-%d')}, inplace = True)\n",
    "        else:\n",
    "            new_hist_fpts_mat = hist_fpts_mat\n",
    "            new_hist_fpts_mat[date_tm1.strftime('%Y-%m-%d')] = float('NaN')\n",
    "        \n",
    "        # write to file\n",
    "        new_hist_fpts_mat.to_csv(str(file_path_date) + \"/hist_fpts_mat_update.csv\", index=False, na_rep=\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create full covariance matrix for entire season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_list = dateRange(datetime.date(2017, 4, 4), datetime.date(2017, 8, 15), datetime.timedelta(days=1))\n",
    "for date in date_list:\n",
    "    # create covariance matrix\n",
    "    file_path_hist = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "    if file_path_hist.exists():\n",
    "        hist_fpts_mat_update = pd.read_csv(str(file_path_hist), header=None)\n",
    "        hist_fpts_mat_update = hist_fpts_mat_update[1:] # remove first row (header)\n",
    "\n",
    "        player_team_vec = hist_fpts_mat_update[0]\n",
    "        player_team_vec = player_team_vec.reset_index(drop=True)\n",
    "\n",
    "        hist_fpts_mat_update = hist_fpts_mat_update.drop(0, 1) # remove first column (names)\n",
    "        hist_fpts_mat_update = hist_fpts_mat_update.astype(float)\n",
    "        cov_mat_masked = np.ma.array(hist_fpts_mat_update, mask=np.isnan(hist_fpts_mat_update))\n",
    "        cov_mat = np.ma.cov(cov_mat_masked, allow_masked=True)\n",
    "        cov_mat = np.ma.getdata(cov_mat)\n",
    "        \n",
    "        # get list of team names in order\n",
    "        column_teams = []\n",
    "        for player_team in player_team_vec:\n",
    "            column_teams.append(player_team.split('_')[1])\n",
    "\n",
    "        # set covariance to 0 if not on same team\n",
    "        for ind_row, player_team in enumerate(player_team_vec):\n",
    "            row_team = player_team_vec[ind_row].split('_')[1]\n",
    "            for ind_col, column_team in enumerate(column_teams):\n",
    "                if row_team != column_team:\n",
    "                    cov_mat[ind_row, ind_col] = 0.0\n",
    "                    \n",
    "        # TODO: set to 0 if less than played in less than 5% of games\n",
    "                    \n",
    "        # convert to pandas df to add column names\n",
    "        cov_mat = pd.DataFrame(cov_mat)\n",
    "        cov_mat.columns = player_team_vec\n",
    "        \n",
    "        # write to file\n",
    "        cov_mat.to_csv(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/covariance_mat_update.csv\", index=False, na_rep=\"NA\")\n",
    "        print(date.strftime('%Y-%m-%d') + \" completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset covariance matrix for each contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-01 $33.00entry_MLB$325KFastball[$50Kto1st] completed\n",
      "2017-05-01 $4.00entry_MLB$175KFour-Seamer[20EntryMax] completed\n",
      "2017-05-01 $333.00entry_MLB$250KSUPERPerfectGame[$50Kto1st] completed\n",
      "2017-05-01 $25.00entry_MLBGIANT$25DoubleUp completed\n",
      "2017-05-01 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-05-01 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-05-01 $1.00entry_MLB$5CincoDeMayoSpecialSUPERSat[200x] completed\n",
      "2017-05-01 $0.25entry_MLB$5CincoDeMayoSpecialSUPERSat[150x] completed\n",
      "2017-05-01 $1.00entry_MLB$3.5MFantasyGolfMillionaireSUPERSat[30x] completed\n",
      "2017-05-01 $10.00entry_MLB$10DoubleUp completed\n",
      "2017-05-01 $2.00entry_MLB$2DoubleUp completed\n",
      "2017-05-01 $9.00entry_MLB$4KSlider completed\n",
      "2017-05-01 $5.00entry_MLB$5KKnuckleball completed\n",
      "2017-05-01 $2.00entry_MLB$2KFlare completed\n",
      "2017-05-01 $2.00entry_MLB$4KFlare completed\n",
      "2017-05-01 $1.00entry_MLB$12.5KSoloShot completed\n",
      "2017-05-01 $0.25entry_MLB$6KQuarterArcade completed\n",
      "2017-05-01 $3.00entry_MLB$7KMoonshot(Turbo) completed\n",
      "2017-05-01 $1.00entry_MLB$1KSoloShot(Turbo) completed\n",
      "2017-05-01 $1.00entry_MLB$1KSoloShot(Turbo) completed\n",
      "2017-05-01 $0.25entry_MLB$750QuarterArcade[Just$0.25!](Turbo) completed\n",
      "2017-05-01 $4.00entry_MLB$15KFour-Seamer(Night) completed\n",
      "2017-05-01 $2.00entry_MLB$1KFlare(Night) completed\n",
      "2017-05-01 $1.00entry_MLB$1.5KSoloShot(Night) completed\n",
      "2017-05-01 $0.25entry_MLB$1KQuarterArcade[Just$0.25!](Night) completed\n",
      "2017-05-02 $8.00entry_MLB$350KCrazy8's completed\n",
      "2017-05-02 $33.00entry_MLB$175KFastball completed\n",
      "2017-05-02 $333.00entry_MLB$200KPerfectGame completed\n",
      "2017-05-02 $4.00entry_MLB$75KFour-Seamer[20EntryMax] completed\n",
      "2017-05-02 $0.25entry_MLB$5CincoDeMayoSpecialSUPERSat[200x] completed\n",
      "2017-05-02 $1.00entry_MLB$5CincoDeMayoSpecialSUPERSat[250x] completed\n",
      "2017-05-02 $25.00entry_MLBGIANT$25DoubleUp completed\n",
      "2017-05-02 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-05-02 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-05-02 $10.00entry_MLB$10DoubleUp completed\n",
      "2017-05-02 $2.00entry_MLB$2DoubleUp completed\n",
      "2017-05-02 $1.00entry_MLB$12.5KSoloShot completed\n",
      "2017-05-02 $1.00entry_MLB$3.5MFantasyGolfMillionaireSUPERSat[30x] completed\n",
      "2017-05-02 $0.25entry_MLB$3.5MFantasyGolfMillionaireSUPERSat[20x] completed\n",
      "2017-05-02 $5.00entry_MLB$4KKnuckleball completed\n",
      "2017-05-02 $2.00entry_MLB$5KFlare completed\n",
      "2017-05-02 $0.25entry_MLB$6KQuarterArcade completed\n",
      "2017-05-02 $3.00entry_MLB$6KMoonshot(Turbo) completed\n",
      "2017-05-02 $1.00entry_MLB$1.5KSoloShot(Turbo) completed\n",
      "2017-05-02 $0.25entry_MLB$1KQuarterArcade[Just$0.25!](Turbo) completed\n",
      "2017-05-02 $3.00entry_MLB$6KMoonshot(Turbo) completed\n",
      "2017-05-02 $1.00entry_MLB$1.5KSoloShot(Turbo) completed\n",
      "2017-05-02 $0.25entry_MLB$1KQuarterArcade[Just$0.25!](Turbo) completed\n",
      "2017-05-02 $8.00entry_MLB$35KCrazy8's(Night) completed\n",
      "2017-05-02 $33.00entry_MLB$15KFastball(Night) completed\n",
      "2017-05-02 $4.00entry_MLB$10KFour-Seamer(Night) completed\n",
      "2017-05-02 $2.00entry_MLB$1KFlare(Night) completed\n",
      "2017-05-02 $1.00entry_MLB$3KSoloShot(Night) completed\n",
      "2017-05-02 $0.25entry_MLB$1.5KQuarterArcade[Just$0.25!](Night) completed\n",
      "2017-05-03 $8.00entry_MLB$350KCrazy8's[$50Kto1st] completed\n",
      "2017-05-03 $33.00entry_MLB$215KFastball completed\n",
      "2017-05-03 $333.00entry_MLB$225KPerfectGame completed\n",
      "2017-05-03 $4.00entry_MLB$75KFour-Seamer[20EntryMax] completed\n",
      "2017-05-03 $25.00entry_MLBGIANT$25DoubleUp completed\n",
      "2017-05-03 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-05-03 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-05-03 $1.00entry_MLB$5CincoDeMayoSpecialSUPERSat[250x] completed\n",
      "2017-05-03 $0.25entry_MLB$5CincoDeMayoSpecialSUPERSat[200x] completed\n",
      "2017-05-03 $1.00entry_MLB$3.5MFantasyGolfMillionaireSUPERSat[30x] completed\n",
      "2017-05-03 $10.00entry_MLB$10DoubleUp completed\n",
      "2017-05-03 $2.00entry_MLB$2DoubleUp completed\n",
      "2017-05-03 $5.00entry_MLB$4KKnuckleball completed\n",
      "2017-05-03 $2.00entry_MLB$5KFlare completed\n",
      "2017-05-03 $1.00entry_MLB$12.5KSoloShot completed\n",
      "2017-05-03 $0.25entry_MLB$6KQuarterArcade completed\n",
      "2017-05-03 $8.00entry_MLB$6KCrazy8's(Turbo) completed\n",
      "2017-05-03 $4.00entry_MLB$2KFour-Seamer(Turbo) completed\n",
      "2017-05-03 $1.00entry_MLB$1.5KSoloShot(Turbo) completed\n",
      "2017-05-03 $0.25entry_MLB$1KQuarterArcade[Just$0.25!](Turbo) completed\n",
      "2017-05-03 $4.00entry_MLB$35KFour-Seamer(Night) completed\n",
      "2017-05-03 $8.00entry_MLB$6KCrazy8's(Turbo) completed\n",
      "2017-05-03 $33.00entry_MLB$20KFastball(Night) completed\n",
      "2017-05-03 $1.00entry_MLB$1.5KSoloShot(Turbo) completed\n",
      "2017-05-03 $0.25entry_MLB$1KQuarterArcade[Just$0.25!](Turbo) completed\n",
      "2017-05-03 $2.00entry_MLB$1KFlare(Night) completed\n",
      "2017-05-03 $1.00entry_MLB$3KSoloShot(Night) completed\n",
      "2017-05-03 $0.25entry_MLB$1.5KQuarterArcade[Just$0.25!](Night) completed\n",
      "2017-05-04 $33.00entry_MLB$150KFastball completed\n",
      "2017-05-04 $4.00entry_MLB$100KFour-Seamer[20EntryMax] completed\n",
      "2017-05-04 $33.00entry_MLB$100KFastball(Early) completed\n",
      "2017-05-04 $4.00entry_MLB$50KFour-Seamer[20EntryMax](Early) completed\n",
      "2017-05-04 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-05-04 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-05-04 $3.00entry_MLB$4KMoonshot(AllDay) completed\n",
      "2017-05-04 $1.00entry_MLB$750SoloShot(AllDay) completed\n",
      "2017-05-04 $0.25entry_MLB$500QuarterArcade[Just$0.25!](AllDay) completed\n",
      "2017-05-04 $5.00entry_MLB$5DoubleUp(Early) completed\n",
      "2017-05-04 $0.25entry_MLB$5CincoDeMayoSpecialSUPERSat[150x](Early) completed\n",
      "2017-05-04 $1.00entry_MLB$5CincoDeMayoSpecialSUPERSat[150x](Early) completed\n",
      "2017-05-04 $0.25entry_MLB$3.5MFantasyGolfMillionaireSUPERSatellite[10x](Early) completed\n",
      "2017-05-04 $2.00entry_MLB$2.5KFlare(Early) completed\n",
      "2017-05-04 $1.00entry_MLB$5KSoloShot(Early) completed\n",
      "2017-05-04 $0.25entry_MLB$2.5KQuarterArcade[Just$0.25!](Early) completed\n",
      "2017-05-04 $3.00entry_MLB$6KMoonshot(Afternoon) completed\n",
      "2017-05-04 $0.25entry_MLB$750QuarterArcade[Just$0.25!](Afternoon) completed\n",
      "2017-05-04 $1.00entry_MLB$1KSoloShot(Afternoon) completed\n",
      "2017-05-04 $1.00entry_MLB$5CincoDeMayoSpecialSUPERSat[350x] completed\n",
      "2017-05-04 $0.25entry_MLB$5CincoDeMayoSpecialSUPERSat[250x] completed\n",
      "2017-05-04 $1.00entry_MLB$3.5MFantasyGolfMillionaireSUPERSatellite[10x] completed\n",
      "2017-05-04 $10.00entry_MLB$10DoubleUp completed\n",
      "2017-05-04 $2.00entry_MLB$2DoubleUp completed\n",
      "2017-05-04 $5.00entry_MLB$2.5KKnuckleball completed\n"
     ]
    }
   ],
   "source": [
    "date_list = dateRange(datetime.date(2017, 5, 1), datetime.date(2017, 6, 30), datetime.timedelta(days=1))\n",
    "\n",
    "for date in date_list:\n",
    "    # read in contests.csv and subset by date\n",
    "    contests_file = pd.read_csv(\"MLB/data_warehouse/contests.csv\")\n",
    "    contests_file = contests_file[(contests_file['Contest_Date'] == date.strftime('%Y-%m-%d'))]\n",
    "    contests_file = contests_file.reset_index()\n",
    "    \n",
    "    for i in range(0, len(contests_file)):\n",
    "        file_path_hist = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "        file_path_date = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d'))\n",
    "        if file_path_hist.exists():\n",
    "            # read in hist_fpts_mat_update (don't actually need this but used for convenience of column names)\n",
    "            hist_fpts_mat_update = pd.read_csv(str(file_path_hist), header=None)\n",
    "\n",
    "            # read in hitters.csv\n",
    "            contest_name = contests_file['Entry_Fee'][i] + \"entry_\" + contests_file['Contest_Name'][i].replace(\" \", \"\")\n",
    "            file_path_hitters =  Path(str(file_path_date) + \"/\" + contest_name + \"/hitters.csv\")\n",
    "            if file_path_hitters.exists():\n",
    "                hitters_df = pd.read_csv(str(file_path_date) + \"/\" + contest_name + \"/hitters.csv\")\n",
    "\n",
    "                # read in covariance_mat_update and update it\n",
    "                covariance_mat_update = pd.read_csv(str(file_path_date) + \"/covariance_mat_update.csv\")\n",
    "\n",
    "                # find indicies of each player in hitters_df in hist_fpts_mat_update\n",
    "                hitters_name_team = hitters_df['Name'] + \"_\" + hitters_df['teamAbbrev']\n",
    "                inds_match = []\n",
    "                for name_team in hitters_name_team:\n",
    "                    inds_match.append(hist_fpts_mat_update[hist_fpts_mat_update[0] == name_team].index.tolist())\n",
    "\n",
    "                # find indicies of missing players (will be 0's in covariance matrix)\n",
    "                inds_missing = []\n",
    "                for i, ind in enumerate(inds_match):\n",
    "                    if (len(ind) == 0):\n",
    "                        inds_missing.append(i)\n",
    "\n",
    "                # append 0's to covariance matrix\n",
    "                inds_added = []\n",
    "                for i in range(0,len(inds_missing)):\n",
    "                    covariance_mat_update.loc[len(covariance_mat_update)] = 0\n",
    "                    covariance_mat_update[len(covariance_mat_update)] = pd.Series(np.zeros(len(covariance_mat_update)), index=covariance_mat_update.index)\n",
    "                    inds_added.append(len(covariance_mat_update)-1)\n",
    "\n",
    "                # fill in inds where no match\n",
    "                for i, ind in enumerate(inds_missing):\n",
    "                    inds_match[ind] = [inds_added[i]]\n",
    "\n",
    "                # unlist for numpy function\n",
    "                inds_match = sum(inds_match, [])\n",
    "\n",
    "                # update covariance matrix\n",
    "                covariance_mat_update = np.array(covariance_mat_update)\n",
    "                covariance_mat_update = covariance_mat_update[np.ix_(inds_match,inds_match)] # subset nxn matrix into mxm\n",
    "                covariance_mat_update = pd.DataFrame(covariance_mat_update)\n",
    "                covariance_mat_update.columns = hitters_name_team # set column names\n",
    "\n",
    "                # write to file\n",
    "                covariance_mat_update.to_csv(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/\" + contest_name + \"/covariance_mat_update.csv\", index=False, na_rep=\"NA\")\n",
    "\n",
    "                # print\n",
    "                print(date.strftime('%Y-%m-%d') + \" \" + contest_name + \" completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
