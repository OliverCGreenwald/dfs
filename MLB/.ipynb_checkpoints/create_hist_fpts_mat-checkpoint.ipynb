{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: set covariance to 0 if less than played in less than 10% of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"/Users/alandu/Documents/DFS/\")\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create first/base case hist_fpts_mat_update matrix (only need to run once at beginning of season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # first date\n",
    "# date = \"2017-04-02\"\n",
    "\n",
    "# results_mat = pd.read_csv(\"MLB/data_warehouse/\" + date + \"/player_results.csv\")\n",
    "# results_mat['Name_Team'] = results_mat['Player'] + \"_\" + results_mat['Team']\n",
    "# results_mat = results_mat[['Name_Team', 'Actual Score']]\n",
    "# results_mat.rename(columns={'Actual Score':date}, inplace = True)\n",
    "# results_mat\n",
    "\n",
    "# results_mat.to_csv(\"MLB/data_warehouse/\" + \"2017-04-03\" + \"/hist_fpts_mat_update.csv\", index=False, na_rep=\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create hist_fpts_mat_update for rest of season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-10 00:00:00\n",
      "2017-07-08\n",
      "2017-07-14 00:00:00\n",
      "2017-07-10\n",
      "2017-07-11\n",
      "2017-07-12\n",
      "2017-07-17 00:00:00\n",
      "2017-07-15\n",
      "2017-08-09 00:00:00\n",
      "2017-08-07\n"
     ]
    }
   ],
   "source": [
    "# this code could be cleaned up. got messy because missing some date folders due to missing data / all star break\n",
    "\n",
    "# rest of dates\n",
    "date_list = [datetime.strptime(\"2017-04-04\", '%Y-%m-%d') + timedelta(days=x) for x in range(0, 130)]\n",
    "\n",
    "for date in date_list:\n",
    "    file_path_date = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d'))\n",
    "    if file_path_date.exists():\n",
    "        date_tm1 = date - timedelta(days=1)\n",
    "        \n",
    "        # read in hist_fpts_mat_update from date t-1\n",
    "        file_path_hist = Path(\"MLB/data_warehouse/\" + date_tm1.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "        if file_path_hist.exists():\n",
    "            hist_fpts_mat = pd.read_csv(str(file_path_hist))\n",
    "        else:\n",
    "            # fill in dates where folder is missing\n",
    "            temp_date = date_tm1 - timedelta(days=1)\n",
    "            file_path_hist = Path(\"MLB/data_warehouse/\" + temp_date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "            num_missing = 1\n",
    "            while (file_path_hist.exists() == False):\n",
    "                temp_date = temp_date - timedelta(days=1)\n",
    "                file_path_hist = Path(\"MLB/data_warehouse/\" + temp_date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "                num_missing += 1\n",
    "            hist_fpts_mat = pd.read_csv(str(file_path_hist))\n",
    "            print(date)\n",
    "            for i in range(0,num_missing):\n",
    "                new_column = temp_date + timedelta(days=i+1)\n",
    "                \n",
    "                # add missing date\n",
    "                new_column_m1 = new_column - timedelta(days=1)\n",
    "                print(new_column_m1.strftime('%Y-%m-%d'))\n",
    "                file_path_results = Path(\"MLB/data_warehouse/\" + new_column_m1.strftime('%Y-%m-%d') + \"/player_results.csv\")\n",
    "                if file_path_results.exists():\n",
    "                    results_mat = pd.read_csv(str(file_path_results))\n",
    "                    results_mat['Name_Team'] = results_mat['Player'] + \"_\" + results_mat['Team']\n",
    "                    hist_fpts_mat = hist_fpts_mat.merge(results_mat[['Name_Team', 'Actual Score']], on=\"Name_Team\", how='outer')\n",
    "                    hist_fpts_mat.rename(columns={'Actual Score':new_column_m1.strftime('%Y-%m-%d')}, inplace = True)\n",
    "                elif Path(\"MLB/data_warehouse/\" + new_column_m1.strftime('%Y-%m-%d')).exists():\n",
    "                    hist_fpts_mat[new_column_m1.strftime('%Y-%m-%d')] = float('NaN')\n",
    "                \n",
    "                # add previous dates NA\n",
    "                hist_fpts_mat[new_column.strftime('%Y-%m-%d')] = float('NaN')\n",
    "        \n",
    "        # add fpts for date t\n",
    "        file_path_results = Path(\"MLB/data_warehouse/\" + date_tm1.strftime('%Y-%m-%d') + \"/player_results.csv\")\n",
    "        if file_path_results.exists():\n",
    "            results_mat = pd.read_csv(str(file_path_results))\n",
    "            results_mat['Name_Team'] = results_mat['Player'] + \"_\" + results_mat['Team']\n",
    "\n",
    "            new_hist_fpts_mat = hist_fpts_mat.merge(results_mat[['Name_Team', 'Actual Score']], on=\"Name_Team\", how='outer')\n",
    "            new_hist_fpts_mat.rename(columns={'Actual Score':date_tm1.strftime('%Y-%m-%d')}, inplace = True)\n",
    "        else:\n",
    "            new_hist_fpts_mat = hist_fpts_mat\n",
    "            new_hist_fpts_mat[date_tm1.strftime('%Y-%m-%d')] = float('NaN')\n",
    "        \n",
    "        # write to file\n",
    "        new_hist_fpts_mat.to_csv(str(file_path_date) + \"/hist_fpts_mat_update.csv\", index=False, na_rep=\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create full covariance matrix for entire season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_list = [datetime.strptime(\"2017-04-04\", '%Y-%m-%d') + timedelta(days=x) for x in range(0, 130)]\n",
    "for date in date_list:\n",
    "    # create covariance matrix\n",
    "    file_path_hist = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "    if file_path_hist.exists():\n",
    "        hist_fpts_mat_update = pd.read_csv(str(file_path_hist), header=None)\n",
    "        hist_fpts_mat_update = hist_fpts_mat_update[1:] # remove first row (header)\n",
    "\n",
    "        player_team_vec = hist_fpts_mat_update[0]\n",
    "        player_team_vec = player_team_vec.reset_index(drop=True)\n",
    "\n",
    "        hist_fpts_mat_update = hist_fpts_mat_update.drop(0, 1) # remove first column (names)\n",
    "        hist_fpts_mat_update = hist_fpts_mat_update.astype(float)\n",
    "        cov_mat_masked = np.ma.array(hist_fpts_mat_update, mask=np.isnan(hist_fpts_mat_update))\n",
    "        cov_mat = np.ma.cov(cov_mat_masked, allow_masked=True)\n",
    "        cov_mat = np.ma.getdata(cov_mat)\n",
    "        \n",
    "        # get list of team names in order\n",
    "        column_teams = []\n",
    "        for player_team in player_team_vec:\n",
    "            column_teams.append(player_team.split('_')[1])\n",
    "\n",
    "        # set covariance to 0 if not on same team\n",
    "        for ind_row, player_team in enumerate(player_team_vec):\n",
    "            row_team = player_team_vec[ind_row].split('_')[1]\n",
    "            for ind_col, column_team in enumerate(column_teams):\n",
    "                if row_team != column_team:\n",
    "                    cov_mat[ind_row, ind_col] = 0.0\n",
    "                    \n",
    "        # TODO: set to 0 if less than played in less than 10% of games\n",
    "                    \n",
    "        # convert to pandas df to add column names\n",
    "        cov_mat = pd.DataFrame(cov_mat)\n",
    "        cov_mat.columns = player_team_vec\n",
    "        \n",
    "        # write to file\n",
    "        cov_mat.to_csv(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/covariance_mat_update.csv\", index=False, na_rep=\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset covariance matrix for each contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-09 $33.00entry_MLB$200KFastball[$30Kto1st] completed\n",
      "2017-08-09 $8.00entry_MLB$115KRallyCap completed\n",
      "2017-08-09 $444.00entry_MLB$250KGrandSlam[$50Kto1st] completed\n",
      "2017-08-09 $4.00entry_MLB$100KFour-Seamer[20EntryMax] completed\n",
      "2017-08-09 $55.00entry_MLB$75KFullCount(Early) completed\n",
      "2017-08-09 $4.00entry_MLB$35KFour-Seamer[20EntryMax](Early) completed\n",
      "2017-08-09 $8.00entry_MLB$30KRallyCap(Early) completed\n",
      "2017-08-09 $5.00entry_LASTSHOT:MLB$3MFantasyGolfMillionaireSUPERSatellite[100x] completed\n",
      "2017-08-09 $7.00entry_LASTSHOT:MLB$3MFantasyGolfMillionaireSUPERSatellite[75x] completed\n",
      "2017-08-09 $1.00entry_LASTSHOT:MLB$3MFantasyGolfMillionaireSUPERSatellite[30x] completed\n",
      "2017-08-09 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-08-09 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-08-09 $2.00entry_MLB$2DoubleUp completed\n",
      "2017-08-09 $1.00entry_MLB$7KSoloShot completed\n",
      "2017-08-09 $2.00entry_MLB$2.5KFlare completed\n",
      "2017-08-09 $0.25entry_MLB$3KQuarterJukebox[Just$0.25!] completed\n",
      "2017-08-09 $0.10entry_MLB$500DimeTime[Just$0.10!] completed\n",
      "2017-08-09 $2.00entry_MLB$1KFlare(Early) completed\n",
      "2017-08-09 $1.00entry_MLB$2.5KSoloShot(Early) completed\n",
      "2017-08-09 $0.25entry_MLB$1KQuarterJukebox[Just$0.25!](Early) completed\n",
      "2017-08-09 $0.10entry_MLB$200DimeTime[Just$0.10!](Early) completed\n",
      "2017-08-09 $0.10entry_MLB$100DimeTime[Just$0.10!](AllDay) completed\n",
      "2017-08-09 $1.00entry_MLB$500SoloShot(AllDay) completed\n",
      "2017-08-09 $0.25entry_MLB$250QuarterJukebox[Just$0.25!](AllDay) completed\n",
      "2017-08-09 $6.00entry_MLB$4KPickle(Afternoon) completed\n",
      "2017-08-09 $4.00entry_MLB$2KFour-Seamer(Afternoon) completed\n",
      "2017-08-09 $1.00entry_MLB$750SoloShot(Afternoon) completed\n",
      "2017-08-09 $0.25entry_MLB$500QuarterJukebox[Just$0.25!](Afternoon) completed\n",
      "2017-08-09 $0.10entry_MLB$100DimeTime[Just$0.10!](Afternoon) completed\n",
      "2017-08-09 $8.00entry_MLB$12KRallyCap[20EntryMax](Night) completed\n",
      "2017-08-09 $4.00entry_MLB$2KFour-Seamer(Night) completed\n",
      "2017-08-09 $2.00entry_MLB$1KFlare(Night) completed\n",
      "2017-08-09 $1.00entry_MLB$1.5KSoloShot(Night) completed\n",
      "2017-08-09 $0.25entry_MLB$1KQuarterJukebox[Just$0.25!](Night) completed\n",
      "2017-08-09 $0.10entry_MLB$100DimeTime[Just$0.10!](Night) completed\n"
     ]
    }
   ],
   "source": [
    "date_list = [datetime.strptime(\"2017-08-09\", '%Y-%m-%d') + timedelta(days=x) for x in range(0, 5)]\n",
    "\n",
    "for date in date_list:\n",
    "    # read in contests.csv and subset by date\n",
    "    contests_file = pd.read_csv(\"MLB/data_warehouse/contests.csv\")\n",
    "    contests_file = contests_file[(contests_file['Contest_Date'] == date.strftime('%Y-%m-%d'))]\n",
    "    contests_file = contests_file.reset_index()\n",
    "    \n",
    "    for i in range(0, len(contests_file)):\n",
    "        file_path_hist = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "        file_path_date = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d'))\n",
    "        if file_path_hist.exists():\n",
    "            # read in hist_fpts_mat_update (don't actually need this but used for convenience of column names)\n",
    "            hist_fpts_mat_update = pd.read_csv(str(file_path_hist), header=None)\n",
    "\n",
    "            # read in hitters.csv\n",
    "            contest_name = contests_file['Entry_Fee'][i] + \"entry_\" + contests_file['Contest_Name'][i].replace(\" \", \"\")\n",
    "            file_path_hitters =  Path(str(file_path_date) + \"/\" + contest_name + \"/hitters.csv\")\n",
    "            if file_path_hitters.exists():\n",
    "                hitters_df = pd.read_csv(str(file_path_date) + \"/\" + contest_name + \"/hitters.csv\")\n",
    "\n",
    "                # read in covariance_mat_update and update it\n",
    "                covariance_mat_update = pd.read_csv(str(file_path_date) + \"/covariance_mat_update.csv\")\n",
    "\n",
    "                # find indicies of each player in hitters_df in hist_fpts_mat_update\n",
    "                hitters_name_team = hitters_df['Name'] + \"_\" + hitters_df['teamAbbrev']\n",
    "                inds_match = []\n",
    "                for name_team in hitters_name_team:\n",
    "                    inds_match.append(hist_fpts_mat_update[hist_fpts_mat_update[0] == name_team].index.tolist())\n",
    "\n",
    "                # find indicies of missing players (will be 0's in covariance matrix)\n",
    "                inds_missing = []\n",
    "                for i, ind in enumerate(inds_match):\n",
    "                    if (len(ind) == 0):\n",
    "                        inds_missing.append(i)\n",
    "\n",
    "                # append 0's to covariance matrix\n",
    "                inds_added = []\n",
    "                for i in range(0,len(inds_missing)):\n",
    "                    covariance_mat_update.loc[len(covariance_mat_update)] = 0\n",
    "                    covariance_mat_update[len(covariance_mat_update)] = pd.Series(np.zeros(len(covariance_mat_update)), index=covariance_mat_update.index)\n",
    "                    inds_added.append(len(covariance_mat_update)-1)\n",
    "\n",
    "                # fill in inds where no match\n",
    "                for i, ind in enumerate(inds_missing):\n",
    "                    inds_match[ind] = [inds_added[i]]\n",
    "\n",
    "                # unlist for numpy function\n",
    "                inds_match = sum(inds_match, [])\n",
    "\n",
    "                # update covariance matrix\n",
    "                covariance_mat_update = np.array(covariance_mat_update)\n",
    "                covariance_mat_update = covariance_mat_update[np.ix_(inds_match,inds_match)] # subset nxn matrix into mxm\n",
    "                covariance_mat_update = pd.DataFrame(covariance_mat_update)\n",
    "                covariance_mat_update.columns = hitters_name_team # set column names\n",
    "\n",
    "                # write to file\n",
    "                covariance_mat_update.to_csv(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/\" + contest_name + \"/covariance_mat_update.csv\", index=False, na_rep=\"NA\")\n",
    "\n",
    "                # print\n",
    "                print(date.strftime('%Y-%m-%d') + \" \" + contest_name + \" completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
